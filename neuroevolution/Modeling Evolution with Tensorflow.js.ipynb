{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is NeuroEvolution?\n",
    "\n",
    "![alt text](https://github.com/nnrg/opennero/wiki/neuroevolution.png \"Logo Title Text 1\")\n",
    "\n",
    "- Machine learning models are in essence function approximators. \n",
    "- Whether it is classification, regression or reinforcement learning, the end goal is almost always to find a function that maps input data to output data. \n",
    "\n",
    "![alt text](http://wiki.ubc.ca/images/6/64/FunctionApproximation_idea.png \"Logo Title Text 1\")\n",
    "\n",
    "- You use the training data to infer the parameters and hyperparameters and verify with the test data whether the approximated function performs well on unseen data.\n",
    "- The core problem is thus finding the parameter settings that results in the lowest loss or the highest reward. \n",
    "- Check this out. The x and y axis represent the 2 parameters of a model and the Z axis is the objective. \n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*cJGKqkLeNW2DsPCoirexCA.png \"Logo Title Text 1\")\n",
    "\n",
    "- How to find the minimum?\n",
    "- Gradient Descent is a classic example. But is there another way?\n",
    "\n",
    "![alt text](https://static.thinkingandcomputing.com/2014/03/bprop.png \"Logo Title Text 1\")\n",
    "\n",
    "- Neuroevolution, genetic algorithms, evolution strategies all revolve around the concept of genetic evolution.\n",
    "- Its the process of evolving neural networks through evolutionary algorithms\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/anoverviewofgradientdescentoptimizationalgorithms-170414055411/95/an-overview-of-gradient-descent-optimization-algorithms-6-638.jpg?cb=1492149859 \"Logo Title Text 1\")\n",
    "\n",
    "Typically it goes like this \n",
    "\n",
    "![alt text](https://www.researchgate.net/profile/Shimon_Whiteson/publication/228529570/figure/fig1/AS:301868958928919@1448982576989/The-basic-steps-of-neuroevolution.png \"Logo Title Text 1\")\n",
    "\n",
    "- Generate a population (say 100) of random neural network. \n",
    "- Randomly determine architecture of each neural network using a gaussian distribution\n",
    "- Select the best neural networks\n",
    "- Breed them\n",
    "- Repeat with the offspring\n",
    "- So instead of a single model, we use several. thats a key difference from gradient descent\n",
    "- NEAT, HyperNEAT, and novelty search are some examples\n",
    "- Evolution strategies, genetic algorithms, etc. all have slightly different approaches as to how genetic optimisation is performed.\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*KQIGKIZOKJudEf9x_sW5Kw.png \"Logo Title Text 1\")\n",
    "\n",
    "- First, a fitness evaluation is performed. \n",
    "- This means checking where the models are in the optimisation surface and determining which of the models perform best (e.g. are the most fit).\n",
    "-  Next, a selection is performed based on the fitness evaluation. \n",
    "- In evolution strategies, the (pseudo) offspring is reduced to a single model, weighted by the fitness evaluation. \n",
    "- For DNN's the fitness is defined as the loss or the reward. \n",
    "- Essentially, you are thus moving around the optimisation surface and using the offspring to get in the right direction. \n",
    "- So instead of computing the gradients, you are setting out multiple 'antenna's' and moving in the direction that looks best. \n",
    "\n",
    "![alt text](https://camo.githubusercontent.com/43eaf9175653a3e5fffd1e79c7aafeb9ca83cc81/68747470733a2f2f76697375616c73747564696f6d6167617a696e652e636f6d2f61727469636c65732f323031342f30332f30312f2537452f6d656469612f4543472f76697375616c73747564696f6d6167617a696e652f496d616765732f323031342f30332f45766f6c7574696f6e617279416c676f726974686d2e61736878 \"Logo Title Text 1\")\n",
    "\n",
    "- In a way, this is similar to a 'structured random' search. \n",
    "- The end result of the selection phase is that you have a single model.\n",
    "- Next, reproduction and combination is performed. \n",
    "- Concretely, the same process as in the initial phase is repeated. \n",
    "- Based on the newly selected 'prime' model, a new set of offspring is derived. \n",
    "- The process then continues with this offspring.\n",
    "- Typically, in genetic optimisation, mutation is also performed in order to improve the variety of the offspring.\n",
    "- The image below represent two of the main differences between ES and gradient descent. Multiple models are used to move around, and gradients are not calculated, rather the different models are averaged based on their performance. \n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*6A6xog-xmjOXe48Mb7WWhQ.png \"Logo Title Text 1\")\n",
    "\n",
    "To summarize, Genetic Algorithms\n",
    "\n",
    "- Creates a population of (randomly generated) members\n",
    "- Scores each member of the population based on some goal. This score is called a fitness function.\n",
    "- Selects and breeds the best members of the population to produce more like them\n",
    "- Mutates some members randomly to attempt to find even better candidates\n",
    "- Kills off the rest (survival of the fittest and all), and\n",
    "- Repeats from step 2. Each iteration through these steps is called a generation.\n",
    "\n",
    "- Repeat this process enough times and you should be left with the very best possible members of a population. \n",
    "\n",
    "Applied to Neural Networks, we can use it to tune 4 parameters\n",
    "\n",
    "- Number of layers (or the network depth)\n",
    "- Neurons per layer (or the network width)\n",
    "- Dense layer activation function\n",
    "- Network optimizer\n",
    "\n",
    "### What are the use cases?\n",
    "\n",
    "- Cars like Uber\n",
    "\n",
    "![alt text](https://eng.uber.com/wp-content/uploads/2017/11/image4-1-1024x574.png \"Logo Title Text 1\")\n",
    "\n",
    "- Better game AI\n",
    "\n",
    "![alt text](https://blog.openai.com/content/images/2017/03/out.gif \"Logo Title Text 1\")\n",
    "\n",
    "- Image Classifiers\n",
    "\n",
    "![alt text](https://techcrunch.com/wp-content/uploads/2016/10/customtraining-adidas.png?w=730&crop=1 \"Logo Title Text 1\")\n",
    "\n",
    "- Art Generation\n",
    "\n",
    "![alt text](http://www.whatsnewonthenet.com/wp-content/uploads/2016/11/googleaiwebsite.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Anything really!\n",
    "\n",
    "### Tensorflow.js Architecture\n",
    "\n",
    "###### Core API (Low Level) - Lets use this\n",
    "\n",
    "- A computational graph is a series of TensorFlow operations arranged into a graph. \n",
    "- The graph is composed of two types of objects.\n",
    "- Operations (or \"ops\"): The nodes of the graph. Operations describe calculations that consume and produce tensors.\n",
    "- Tensors: The edges in the graph. These represent the values that will flow through the graph. Most TensorFlow functions return tf.Tensors.\n",
    "\n",
    "```javascript\n",
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0) # also tf.float32 implicitly\n",
    "total = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)\n",
    "```\n",
    "\n",
    "###### Layers (high level) \n",
    "\n",
    "- Layers package together both the variables and the operations that act on them. \n",
    "- For example a densely-connected layer performs a weighted sum across all inputs for each output and applies an optional activation function. \n",
    "- The connection weights and biases are managed by the layer object.\n",
    "- The following code creates a Dense layer that takes a batch of input vectors, and produces a single output value for each. \n",
    "- To apply a layer to an input, call the layer as if it were a function. For example:\n",
    "\n",
    "```javascript\n",
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "y = linear_model(x)\n",
    "```\n",
    "\n",
    "### Our Model\n",
    "\n",
    "- All creatures have a 3 layer feed-forward Neural Network as their brain\n",
    "- The topology is 4 - 100 - X, where the number of nodes X in the output layer depend on the number of muscles of the creature. \n",
    "- The input data fed to the network are:\n",
    "\n",
    "- Horizontal velocity\n",
    "- Vertical Velocity\n",
    "- Torque\n",
    "- Height above the ground level\n",
    "\n",
    "###### Score \n",
    "- A creature can gain points based on the distance it travels from the starting point.\n",
    "- The further it travels in the correct direction, the more point it gains. \n",
    "- Traveling in the opposite direction, will reduce the point.\n",
    "\n",
    "###### Fitness Function \n",
    "- The further the creatures go to the right the more they are rewarded\n",
    "\n",
    "###### Selection Algorithm\n",
    "- The creatures are selected for breeding based on their fitness value. \n",
    "- The fitness value acts like a probability of being chosen for reproduction. \n",
    "- Creatures that perform better have higher fitness value and hence has higher chance of reproducing.\n",
    "\n",
    "###### Crossover:\n",
    "\n",
    "- Two creatures (parents) are selected using the selection algorithm. \n",
    "- Their weights are interchanged randomly bit wise as shown in the picture below to form a new set of weights.\n",
    "- In our case, a single bit represents a single weight. This new set of weights is used to form a new creature (child).\n",
    "\n",
    "![alt text](https://camo.githubusercontent.com/82b85caee5d382d8f4959af6acd6fed8ccca93b0/68747470733a2f2f7374617469632e7468696e6b696e67616e64636f6d707574696e672e636f6d2f323031342f30332f63726f73736f7665722e706e67 \"Logo Title Text 1\")\n",
    "\n",
    "###### Mutation \n",
    "\n",
    "- The mutation rate, which is usually about 1 - 2%, is in fact the probability of introduction of randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
